{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_seeker = pd.read_csv(\"TruthSeeker2023/Features_For_Traditional_ML_Techniques.csv\")\n",
    "truth_seeker = truth_seeker.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of column headings: ['majority_target', 'statement', 'BinaryNumTarget', 'tweet', 'followers_count', 'friends_count', 'favourites_count', 'statuses_count', 'listed_count', 'following', 'embeddings', 'BotScore', 'BotScoreBinary', 'cred', 'normalize_influence', 'mentions', 'quotes', 'replies', 'retweets', 'favourites', 'hashtags', 'URLs', 'unique_count', 'total_count', 'ORG_percentage', 'NORP_percentage', 'GPE_percentage', 'PERSON_percentage', 'MONEY_percentage', 'DATE_percentage', 'CARDINAL_percentage', 'PERCENT_percentage', 'ORDINAL_percentage', 'FAC_percentage', 'LAW_percentage', 'PRODUCT_percentage', 'EVENT_percentage', 'TIME_percentage', 'LOC_percentage', 'WORK_OF_ART_percentage', 'QUANTITY_percentage', 'LANGUAGE_percentage', 'Word count', 'Max word length', 'Min word length', 'Average word length', 'present_verbs', 'past_verbs', 'adjectives', 'adverbs', 'adpositions', 'pronouns', 'TOs', 'determiners', 'conjunctions', 'dots', 'exclamation', 'questions', 'ampersand', 'capitals', 'digits', 'long_word_freq', 'short_word_freq']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of column headings\n",
    "column_headings = truth_seeker.columns.tolist()\n",
    "\n",
    "# Print or use the list as needed\n",
    "print(\"List of column headings:\", column_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree Classifier: 0.5604172876304024\n",
      "\n",
      "Classification Report for Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.40      0.47     16293\n",
      "         1.0       0.56      0.72      0.63     17257\n",
      "\n",
      "    accuracy                           0.56     33550\n",
      "   macro avg       0.56      0.56      0.55     33550\n",
      "weighted avg       0.56      0.56      0.55     33550\n",
      "\n",
      "Accuracy for Random Forest Classifier: 0.5608047690014903\n",
      "\n",
      "Classification Report for Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.39      0.47     16293\n",
      "         1.0       0.56      0.72      0.63     17257\n",
      "\n",
      "    accuracy                           0.56     33550\n",
      "   macro avg       0.56      0.56      0.55     33550\n",
      "weighted avg       0.56      0.56      0.55     33550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truth_seeker_content = truth_seeker[[\"unique_count\", \"present_verb\", \"total_count\", \"past_verb\", \"ORG_percent\", \"adjectives\", \n",
    "                                     \"NORP_percent\", \"pronouns\", \"GPE_percent\", \"TOâ€™s\", \"PERSON_percent\", \"determiners\", \n",
    "                                     \"MONEY_percent\", \"conjunctions\", \"DATA_percent\", \"dots\", \"CARDINAL_percent\", \"exclamations\", \n",
    "                                     \"PERCENT_percent\", \"question\", \"ORDINAL_percent\", \"ampersand\", \"FAC_percent\", \"capitals\", \n",
    "                                     \"LAW_percent\", \"quotes\", \"PRODUCT_percent\", \"digits\", \"EVENT_percent\", \"long_word_freq\", \n",
    "                                     \"normalized_influence\", \"TIME_percent\", \"short_word_freq\", \"LOC_percent\", \"ORG_percent\", \n",
    "                                     \"WORK_OF_ART_percent\", \"QUANTITY_percent\", \"LANGUAGE_percent\", \"Max Word\", \"Min Word\", \n",
    "                                     \"Avg Word Length\"]]\n",
    "truth_seeker_user = truth_seeker[[\"GPE_percentage\", \"PERSON_percentage\"]]\n",
    "truth_seeker_spaCy = truth_seeker[[\"ORG_percent\", \"NORP_percent\", \"GPE_percent\", \"PERSON_percent\", \"MONEY_percent\", \"DATA_percent\", \n",
    "                                   \"CARDINAL_percent\", \"PERCENT_percent\", \"ORDINAL_percent\", \"FAC_percent\", \"LAW_percent\", \n",
    "                                   \"PRODUCT_percent\", \"EVENT_percent\", \"TIME_percent\", \"LOC_percent\", \"ORG_percent\", \n",
    "                                   \"WORK_OF_ART_percent\", \"QUANTITY_percent\", \"LANGUAGE_percent\"]]\n",
    "\n",
    "truth_seeker_output = truth_seeker[\"BinaryNumTarget\"]\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    truth_seeker_input,\n",
    "    truth_seeker_output,\n",
    "    test_size=0.25,  # Adjust the test_size as needed\n",
    "    random_state=100  # You can set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Now, X_train and y_train are your training data, and X_test and y_test are your testing data\n",
    "\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, y_train)\n",
    "results = model_tree.predict(X_test)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, results)\n",
    "classification_rep_tree = classification_report(y_test, results)\n",
    "\n",
    "# Print or use the evaluation metrics\n",
    "print(\"Accuracy for Decision Tree Classifier:\", accuracy_tree)\n",
    "print(\"\\nClassification Report for Decision Tree Classifier:\\n\", classification_rep_tree)\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "results_rf = model_rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, results_rf)\n",
    "classification_rep_rf = classification_report(y_test, results_rf)\n",
    "\n",
    "# Print or use the evaluation metrics\n",
    "print(\"Accuracy for Random Forest Classifier:\", accuracy_rf)\n",
    "print(\"\\nClassification Report for Random Forest Classifier:\\n\", classification_rep_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Support Vector Classifier: 0.5585692995529061\n",
      "\n",
      "Classification Report for Support Vector Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.41      0.47     16293\n",
      "         1.0       0.56      0.70      0.62     17257\n",
      "\n",
      "    accuracy                           0.56     33550\n",
      "   macro avg       0.56      0.55      0.55     33550\n",
      "weighted avg       0.56      0.56      0.55     33550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_svc = SVC()\n",
    "model_svc.fit(X_train_scaled, y_train)\n",
    "results_svc = model_svc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy_svc = accuracy_score(y_test, results_svc)\n",
    "classification_rep_svc = classification_report(y_test, results_svc)\n",
    "\n",
    "# Print or use the evaluation metrics for SVM\n",
    "print(\"\\nAccuracy for Support Vector Classifier:\", accuracy_svc)\n",
    "print(\"\\nClassification Report for Support Vector Classifier:\\n\", classification_rep_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
